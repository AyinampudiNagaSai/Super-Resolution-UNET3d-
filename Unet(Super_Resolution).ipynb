{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet(Super_Resolution).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhp9cG4gv5uv",
        "colab_type": "code",
        "outputId": "6d0fb0d7-fa49-484d-a435-6b404723e2e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!pip install nibabel\n",
        "!pip install glob\n",
        "!pip install nilearn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.6/dist-packages (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.6/dist-packages (from nibabel) (1.18.4)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement glob (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for glob\u001b[0m\n",
            "Requirement already satisfied: nilearn in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: nibabel>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from nilearn) (3.0.2)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from nilearn) (0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from nilearn) (0.15.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19 in /usr/local/lib/python3.6/dist-packages (from nilearn) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from nilearn) (1.18.4)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.6/dist-packages (from nilearn) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7meQJTQwfvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing required libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import glob\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO-_sjc9wqWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#defining path for required files\n",
        "path_1 = glob.glob('/content/drive/My Drive/selected_1mm^3/*')\n",
        "path_112 = glob.glob('/content/drive/My Drive/selected_112mm^3/*')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYAAOfK_xcTp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#read images from paths\n",
        "images_isotropic = []\n",
        "images_downsampled = []\n",
        "\n",
        "for images in path_1:\n",
        "  data_isotropic = nib.load(images)\n",
        "  data_isotropic = data_isotropic.get_fdata()\n",
        "  images_isotropic.append(data_isotropic)\n",
        "\n",
        "for images in path_112:\n",
        "  data_downsampled = nib.load(images)\n",
        "  data_downsampled = data_downsampled.get_fdata()\n",
        "  images_downsampled.append(data_downsampled)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNYeR50byEBi",
        "colab_type": "code",
        "outputId": "d4901393-6a38-4859-a3e2-6d3ac08a393d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#verifying shapes of isotropic and downsampled images\n",
        "print(images_isotropic[1].shape) \n",
        "print(images_downsampled[1].shape) "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(239, 239, 162)\n",
            "(239, 239, 81)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIH3mLvt9KL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get arrays for isotropic and downsampled images\n",
        "array_images_isotropic = np.asarray(images_isotropic)\n",
        "array_images_downsampled = np.asarray(images_downsampled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOvMDSvc9Zod",
        "colab_type": "code",
        "outputId": "0ade722a-3d2c-4c1f-9ebd-bb049dbb208b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(array_images_isotropic.shape)\n",
        "print(array_images_downsampled.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 239, 239, 162)\n",
            "(2, 239, 239, 81)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKf5KGHUZfhe",
        "colab_type": "code",
        "outputId": "f93e7260-4b61-4071-928f-2f334519391d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        " # getting images in BCDHW format\n",
        "labels = []\n",
        "input_images = []\n",
        "for x,y in zip(array_images_isotropic,array_images_downsampled):\n",
        "  swapped_labels = np.moveaxis(x, 2, 0)\n",
        "  swapped_input_images = np.moveaxis(y, 2, 0)\n",
        "  labels_expand = np.expand_dims(swapped_labels, 0)\n",
        "  labels_expand = np.expand_dims(labels_expand, 0)\n",
        "  input_expand = np.expand_dims(swapped_input_images, 0)\n",
        "  input_expand = np.expand_dims(input_expand, 0)\n",
        "  labels.append(labels_expand)\n",
        "  input_images.append(input_expand)\n",
        "print(len(labels), labels[1].shape)\n",
        "print(len(input_images),input_images[1].shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 (1, 1, 162, 239, 239)\n",
            "2 (1, 1, 81, 239, 239)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HL-2d7Dsb73L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "array_labels = np.asarray(labels)\n",
        "array_input_images = np.asarray(input_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgrklKKZ0ljj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split Train and Test data for validation\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(array_input_images, array_labels, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFMgu5kn1m2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.asarray(X_train)\n",
        "X_train = X_train.astype(np.float64)\n",
        "X_test = np.asarray(X_test)\n",
        "X_test = X_test.astype(np.float64)\n",
        "Y_train = np.asarray(Y_train)\n",
        "Y_train = Y_train.astype(np.float64)\n",
        "Y_test = np.asarray(Y_test)\n",
        "Y_test = Y_test.astype(np.float64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZQWjWXC1Z_I",
        "colab_type": "code",
        "outputId": "2c14ea35-fdab-4156-f8d7-02c8ec826610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#converting numpy array to torch tensors\n",
        "torch_x_train = torch.from_numpy(X_train)\n",
        "torch_y_train = torch.from_numpy(Y_train)\n",
        "torch_x_test = torch.from_numpy(X_test)\n",
        "torch_y_test = torch.from_numpy(Y_test)\n",
        "print(torch_x_train.shape,torch_y_train.shape)\n",
        "print(torch_x_test.shape,torch_y_test.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1, 1, 81, 239, 239]) torch.Size([1, 1, 1, 162, 239, 239])\n",
            "torch.Size([1, 1, 1, 81, 239, 239]) torch.Size([1, 1, 1, 162, 239, 239])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6hUsX2WAwxN",
        "colab_type": "code",
        "outputId": "996add26-c060-4bea-a2c9-061317b8d784",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#mapping train data in train_loader\n",
        "train_loader = []\n",
        "for i, j in zip(torch_x_train, torch_y_train):\n",
        "    train = (i,j)\n",
        "    train_loader.append(train)\n",
        "print(len(train_loader))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBLp6zevBOMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#mapping test data in test_loader\n",
        "test_loader = []\n",
        "for i, j in zip(torch_x_test, torch_y_test):\n",
        "    test = (i,j)\n",
        "    test_loader.append(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm_m9RpZQ4Bj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#deleting unwanted variables\n",
        "del(path_1, path_112, images_isotropic,images_downsampled,array_images_isotropic,array_images_downsampled,labels,input_images)\n",
        "del(array_labels,array_input_images,X_train,X_test,Y_train,Y_test)\n",
        "del(torch_x_train,torch_x_test,torch_y_train,torch_y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6Pb5pwXBSI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1n4Kmq7BW-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_conv_bn_relu(in_channels, out_channels, kernel_size=3, padding=1):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv3d(in_channels, out_channels, kernel_size=kernel_size, padding=padding),\n",
        "        nn.BatchNorm3d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "\n",
        "def create_double_conv(in_channels, mid_channels, out_channels, kernel_size=3, padding=1):\n",
        "    return nn.Sequential(\n",
        "        create_conv_bn_relu(in_channels, mid_channels, kernel_size, padding),\n",
        "        create_conv_bn_relu(mid_channels, out_channels, kernel_size, padding),\n",
        "    )\n",
        "\n",
        "def upsample(x1):\n",
        "    return torch.nn.functional.interpolate(\n",
        "        x1,\n",
        "        size=(2*(x1.size()[2]), x1.size()[3], x1.size()[4]),\n",
        "        scale_factor=None,\n",
        "        mode='trilinear',\n",
        "        align_corners=True\n",
        "    )\n",
        "\n",
        "def upsample_1(x1, x2):\n",
        "    return torch.nn.functional.interpolate(\n",
        "        x1,\n",
        "        size=(x2.size()[2], x2.size()[3], x2.size()[4]),\n",
        "        scale_factor=None,\n",
        "        mode='trilinear',\n",
        "        align_corners=True\n",
        "    )\n",
        " \n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, output_channels):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        self.n_channels = n_channels\n",
        "        self.output_channels = output_channels\n",
        "\n",
        "        self.double_conv_down_0 = create_double_conv(1, 10, 10)\n",
        "        self.double_conv_down_1 = create_double_conv(10, 10, 10)\n",
        "        self.double_conv_down_2 = create_double_conv(10, 10, 10)\n",
        "        self.double_conv_down_3 = create_double_conv(10, 10, 10)\n",
        "        self.double_conv_down_4 = create_double_conv(10, 10, 10)\n",
        "\n",
        "        self.maxpool_1 = nn.MaxPool3d((1, 2, 2))\n",
        "        self.maxpool_2 = nn.MaxPool3d((1, 2, 2))\n",
        "        self.maxpool_3 = nn.MaxPool3d((1, 2, 2))\n",
        "        self.maxpool_4 = nn.MaxPool3d((1, 2, 2))\n",
        "\n",
        "        self.double_conv_up_1 = create_double_conv(20, 10, 10)\n",
        "        self.double_conv_up_2 = create_double_conv(20, 10, 10)\n",
        "        self.double_conv_up_3 = create_double_conv(20, 10, 10)\n",
        "        self.double_conv_up_4 = create_double_conv(20, 10, 10)\n",
        "\n",
        "        self.output_conv = nn.Conv3d(1, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = upsample(x)\n",
        "        x1 = self.double_conv_down_0(x)\n",
        "        x = self.maxpool_1(x1)\n",
        "        x2 = self.double_conv_down_1(x)\n",
        "        x = self.maxpool_2(x2)\n",
        "        x3 = self.double_conv_down_2(x)\n",
        "        x = self.maxpool_3(x3)\n",
        "        x4 = self.double_conv_down_3(x)\n",
        "        x = self.maxpool_4(x4)\n",
        "        x5 = self.double_conv_down_4(x)\n",
        "\n",
        "        x = upsample_1(x5, x4)\n",
        "        x = torch.cat([x, x4], dim=1)\n",
        "        x = self.double_conv_up_1(x)\n",
        "\n",
        "        x = upsample_1(x, x3)\n",
        "        x = torch.cat([x, x3], dim=1)\n",
        "        x = self.double_conv_up_2(x)\n",
        "\n",
        "        x = upsample_1(x, x2)\n",
        "        x = torch.cat([x, x2], dim=1)\n",
        "        x = self.double_conv_up_3(x)\n",
        "\n",
        "        x = upsample_1(x, x1)\n",
        "        x = torch.cat([x, x1], dim=1)\n",
        "        x = self.double_conv_up_4(x)\n",
        "\n",
        "        output = self.output_conv(x)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViypOm4sVuy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = UNet(10,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "updeNjk9eZuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_function = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiNzU8DLfiWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5EixGapfpB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#looping training data for training\n",
        "for epoch in range(2):  \n",
        "\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i,[inputs, labels] in enumerate(train_loader):\n",
        "        outputs = model(inputs.float())\n",
        "        optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_function(outputs, labels.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[{}, {}] loss: {}'.format(epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "       \n",
        "        \"\"\"if i % 10000 == 0:\n",
        "            torch.save(model.state_dict(), <PATH>)\"\"\"\n",
        "\n",
        "        if i % 10000 == 0:\n",
        "            test_loss = []\n",
        "            for inputs, labels in test_loader: # TODO Add test_loader\n",
        "                outputs = model(inputs.float())\n",
        "                loss = loss_function(outputs, labels.float())\n",
        "                # we do not update model here\n",
        "                test_loss.append(loss)\n",
        "            print ('Loss on test set = {}'.format(sum(test_loss) / len(test_loss)))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}